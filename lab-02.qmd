---
title: "Lab 2 - Data wrangling"
author: "Fahad Khalid"
date: "Feb 12 2026"
format: 
  html: default # for speed
  pdf: default # for final output

---


```{r}
#| eval: true
#| message: false

library(tidyverse)
```


# Questions

## Part 1

```{r}
midwest |>
  count(state, sort = TRUE)
```

### Question 1
Illinois (IL) has the most at 102, and Indiana (IN) has the second most at 92. Wisconsin (WI) has the fewest at 72.

\newpage

### Question 2
If a county can't repeat in the same state, if a county name appears in the data 5 times, it must be in every state.
```{r}
midwest |>
  count(county) |>
  filter(n == 5)
```

\newpage

### Question 3a
```{r}
midwest |>
  filter(popdensity > 25000) |>
  select(county, state, popdensity, poptotal, area) |>
  arrange(desc(popdensity))
```
### Question 3b
```{r}
midwest |>
  filter(popdensity == max(popdensity)) |>
  select(county, state, popdensity, poptotal, area)
```
\newpage
### Question 4
```{r}
midwest |>
  summarize(
    typical = median(popdensity),
    lower = quantile(popdensity, 0.25),
    upper = quantile(popdensity, 0.75)
  )
```
The distribution of population density of counties is unimodal and extremely right-skewed (which is why we used median for typical population density). A typical Midwestern county has population density of 1156 people per unit area. The middle 50% of the counties have population densities between 622 to 2330 people per unit area.
\newpage

### Question 5
```{r}
midwest |>
  mutate(metro = if_else(inmetro == 1, "Yes", "No")) |>
  count(state, metro) |>
  group_by(state) |>
  mutate(prop = n / sum(n)) |>
  filter(metro == "Yes")
```

\newpage

### Question 6
```{r}
midwest |>
  filter(percollege < 10, percbelowpoverty > 45) |>
  select(county, state, percbelowpoverty, percollege)
```
```{r}
midwest |>
  filter(percollege > 40, percbelowpoverty < 20) |>
  select(county, state, percbelowpoverty, percollege)
```
```{r}

midwest |>
  filter((percollege < 10 & percbelowpoverty > 45) | 
         (percollege > 40 & percbelowpoverty < 20)) |>
  select(county, state, percbelowpoverty, percollege)
```
```{r}
midwest <- midwest |>
  mutate(potential_outlier = if_else(
    (percollege < 10 & percbelowpoverty > 45) | (percollege > 40 & percbelowpoverty < 20),
    "Yes",
    "No"
  ))

midwest |>
  select(county, state, percbelowpoverty, percollege, potential_outlier) |>
  arrange(potential_outlier)
```
```{r}
ggplot(midwest, aes(x = percollege, y = percbelowpoverty, color = potential_outlier)) +
  geom_point() +
  labs(
    x = "% college educated",
    y = "% below poverty",
    title = "Percentage with a college degree versus poverty rate",
    subtitle = "by State in the Midwest",
    color = "Potential Outlier"
  )
```

\newpage

### Question 7
```{r}
state_population <- midwest |>
  group_by(state) |>
  summarize(total_pop = sum(poptotal)) |>
  arrange(desc(total_pop))


```


```{r}
#B) add proportion
state_population |>
  mutate(prop = total_pop / sum(total_pop))
```
IL (Illinois) is the most populous state, containing approximately 27.2% of the Midwest population. WI (Wisconsin) is the least populous, containing approximately 11.6% of the population.
\newpage

### Question 8
```{r}
state_poverty <- midwest |>
  group_by(state) |>
  summarize(mean_percbelowpoverty = mean(percbelowpoverty))

state_poverty
```

```{r}
state_poverty |>
  arrange(mean_percbelowpoverty)
```
Indiana has the lowest average percentage below poverty (10.3%), while Minnesota has the highest average percentage below poverty (14.2%).
\newpage
## Part 2


### Question 9

```{r}
df <- tibble(
  var_1 = c(10, 20, 30, 40, 50),
  var_2 = c("Pizza", "Burger", "Pizza", "Pizza", "Burger"),
  var_3 = c("Apple", "Apple", "Pear", "Pear", "Banana")
)

df
```
a.
```{r}
df |>
  arrange(var_2)
```


This code rearranges the rows of the dataframe alphabetically based on the values in var_2. arrange() just shuffles the order of the rows for visual purposes but doesn't actually perform any calculations or logical grouping.

b.
```{r}
df |>
  group_by(var_2)
```


This code tags the data into groups based on var_2 (Pizza and Burger). Visually, the output looks exactly the same as the original dataframe. However, in the background R now recognizes the data as being split into groups. This is different from arrange() because arrange() changes the physical order of rows, but group_by() changes how future functions (like summarize) will treat the data without moving the rows.

c.
```{r}
df |>
  group_by(var_2) |>
  summarize(mean_var_1 = mean(var_1))
```

This pipeline groups the data by var_2 and then collapses it using summarize. It calculates the mean of var_1 for "Pizza" and the mean of var_1 for "Burger". The result is a smaller dataframe with only 2 rows (one for each group) and their averages.

d.
```{r}
df |>
  group_by(var_2, var_3) |>
  summarize(mean_var_1 = mean(var_1))
```

This groups the data by two variables (var_2 and var_3) and calculates the mean. The message says "summarise() has grouped output by 'var_2'". This means that summarize usually takes one layer of grouping at a time. After calculating the results, the dataframe is no longer grouped by var_3, but it is still grouped by var_2.

e.
```{r}
df |>
  group_by(var_2, var_3) |>
  summarize(mean_var_1 = mean(var_1), .groups = "drop")
```

This pipeline performs the summary calculation but includes the argument .groups = "drop". This argument explicitly tells R to remove all grouping tags after the summary is finished. The output is a ungrouped dataframe, unlike the output in part (d) was still grouped by var_2.

f.
```{r}
df |>
  group_by(var_2, var_3) |>
  summarize(mean_var_1 = mean(var_1), .groups = "drop")

df |>
  group_by(var_2, var_3) |>
  mutate(mean_var_1 = mean(var_1))
```

The outputs are different in structure (aka dimensions).
The first pipeline (summarize) collapses the data. It returns a smaller dataframe which only has the unique combinations of groups (like Pizza/Apple, Burger/Banana) and the calculated mean.
The second pipeline (mutate) keeps the original dataframe size (5 rows). Instead of collapsing the data, it adds a new column called mean_var_1 and repeats the group's average for every single row belonging to that group.
